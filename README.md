# TYUT - Deepfake Detection Project

## ä½œè€…
è–›é›…ä¸½ã€å¼ ä½³ç¦ã€æ›¹æ™“å³°

## é¡¹ç›®ç®€ä»‹
æœ¬é¡¹ç›®é’ˆå¯¹AIGCä¼ªé€ å›¾åƒæ£€æµ‹ä»»åŠ¡ï¼Œæå‡ºäº†ä¸€ç§åŸºäºCLIP:ViT-L/14çš„ç«¯åˆ°ç«¯æ£€æµ‹ç®—æ³•ã€‚é€šè¿‡SRFormerå›¾åƒå¢å¼ºã€ç›‘ç£å¯¹æ¯”å­¦ä¹ å’ŒSAMä¼˜åŒ–å™¨ç­‰å…³é”®æŠ€æœ¯ï¼Œæ˜¾è‘—æå‡äº†æ¨¡å‹å¯¹å¾®å°ä¼ªé€ ç‰¹å¾çš„è¯†åˆ«èƒ½åŠ›å’Œæ³›åŒ–æ€§èƒ½ã€‚
<img width="2074" height="509" alt="cb26282ea7fff3d4007ced3588e2b635" src="https://github.com/user-attachments/assets/dda684b1-11c6-4ff6-8e49-79ac5d5c22f3" />

---

## ğŸ¯ ç®—æ³•ç®€ä»‹

æœ¬ç®—æ³•ä»¥CLIP:ViT-L/14ä¸ºæ ¸å¿ƒç‰¹å¾æå–å™¨ï¼Œé‡‡ç”¨ç«¯åˆ°ç«¯æµç¨‹å®ç°ä¼ªé€ å›¾åƒæ£€æµ‹ã€‚æ ¸å¿ƒæµç¨‹åŒ…æ‹¬ï¼š
1. **å›¾åƒé¢„å¤„ç†**ï¼šè¾“å…¥å›¾åƒç»SRFormerè¿›è¡Œå›¾åƒé¢„å¢å¼ºï¼Œé‡æ„é«˜é¢‘éƒ¨åˆ†ä¸ç»“æ„ä¿¡æ¯
2. **æ•°æ®å¢å¼º**ï¼šé‡‡ç”¨éšæœºé«˜æ–¯æ¨¡ç³Šã€JPEGå‹ç¼©ç­‰å¤šç»´æ•°æ®å¢å¼ºå¤„ç†
3. **ç‰¹å¾æå–**ï¼šé€šè¿‡CLIP:ViT-L/14æå–768ç»´é«˜å±‚è¯­ä¹‰ç‰¹å¾
4. **åŒåˆ†æ”¯è®¾è®¡**ï¼š
   - åˆ†ç±»å¤´è¾“å‡ºåˆ†ç±»é¢„æµ‹åˆ†æ•°
   - æŠ•å½±å¤´æ˜ å°„ä¸º128ç»´å¯¹æ¯”ç‰¹å¾
5. **è”åˆä¼˜åŒ–**ï¼šåˆ†ç±»æŸå¤±ä¸å¯¹æ¯”å­¦ä¹ æŸå¤±è”åˆæ„å»ºæ€»æŸå¤±ï¼Œä½¿ç”¨SAMä¼˜åŒ–å™¨è¿›è¡Œå‚æ•°æ›´æ–°

---

## ğŸ“‚ é¡¹ç›®ç»“æ„

```text
aigc_fake_detect/
â”œâ”€â”€ checkpoints/                 # æ¨¡å‹æ£€æŸ¥ç‚¹ä¿å­˜ç›®å½•
â”‚   â””â”€â”€ clip_vitl14/            # CLIP ViT-L/14è®­ç»ƒç»“æœ
â”œâ”€â”€ data/                       # åŸå§‹æ•°æ®ç›®å½•
â”œâ”€â”€ datasets/                   # å¤„ç†åçš„æ•°æ®é›†ç›®å½•
â”‚   â”œâ”€â”€ test/                  # æµ‹è¯•é›†æ•°æ®
â”‚   â”œâ”€â”€ train/                 # è®­ç»ƒé›†æ•°æ®  
â”‚   â””â”€â”€ val/                   # éªŒè¯é›†æ•°æ®
â”œâ”€â”€ models/                     # æ¨¡å‹æ¶æ„å®šä¹‰
â”‚   â”œâ”€â”€ clip/                  # CLIPæ¨¡å‹ç›¸å…³
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ clip_models.py         # CLIPæ¨¡å‹å®ç°
â”‚   â”œâ”€â”€ imagenet_models.py     # ImageNeté¢„è®­ç»ƒæ¨¡å‹
â”‚   â”œâ”€â”€ resnet.py              # ResNetæ¶æ„
â”‚   â”œâ”€â”€ vgg.py                 # VGGæ¶æ„
â”‚   â”œâ”€â”€ vision_transformer.py  # Vision Transformeræ¶æ„
â”œâ”€â”€ networks/                   # ç½‘ç»œç»„ä»¶å’Œè®­ç»ƒé€»è¾‘
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ base_model.py          # åŸºç¡€æ¨¡å‹ç±»
â”‚   â”œâ”€â”€ contrastive_loss.py    # å¯¹æ¯”æŸå¤±å‡½æ•°
â”‚   â”œâ”€â”€ sam.py                 # SAMæ¨¡å‹é›†æˆ
â”‚   â””â”€â”€ trainer.py             # è®­ç»ƒå™¨ç±»
â”œâ”€â”€ options/                    # é…ç½®æ–‡ä»¶ç›®å½•
â”œâ”€â”€ your_result_folder/        # ç»“æœä¿å­˜ç›®å½•
â”œâ”€â”€ train.py                   # è®­ç»ƒè„šæœ¬
â”œâ”€â”€ validate.py                # éªŒè¯è„šæœ¬
â”œâ”€â”€ requirements.txt           # ç¯å¢ƒä¾èµ–æ–‡ä»¶
â””â”€â”€ README.md
```
## ğŸ“¥ æ•°æ®ä¸‹è½½ä¸åˆ’åˆ†
æ•°æ®é›†ä¸‹è½½
æœ¬ç®—æ³•ä½¿ç”¨è®ºæ–‡ã€ŠTowards Universal Fake Image Detectors that Generalize Across Generative Modelsã€‹å®˜æ–¹æä¾›çš„è®­ç»ƒæ•°æ®é›†ã€‚
åŸºçº¿æ•°æ®é›†ä¸‹è½½åœ°å€ï¼šhttps://github.com/peterwang512/CNNDetection
åŸºçº¿æ•°æ®é›†å¤§å°: çº¦72GB

é™¤äº†åŸºçº¿æ•°æ®é›†ä»¥å¤–ï¼Œæˆ‘ä»¬è¿˜æä¾›äº†æ›´ä¸ºä¸°å¯Œçš„æ•°æ®é›†ã€‚ä¸ºäº†æ–¹ä¾¿å¤§å®¶æå‡æ¨¡å‹çš„æ€§èƒ½ï¼Œæˆ‘ä»¬ä¹Ÿå°†è¿™äº›æ•°æ®é›†æ•´ç†äº†å‡ºæ¥ï¼Œæ–¹ä¾¿å¤§å®¶è¿›è¡Œä¸‹è½½è®­ç»ƒã€‚
AI Generated Images vs Real Imagesï¼š
https://www.kaggle.com/datasets/cashbowman/ai-generated-images-vs-real-images

CIFAKE: Real and AI-Generated Synthetic Imagesï¼š
https://www.kaggle.com/datasets/birdy654/cifake-real-and-ai-generated-synthetic-images

æˆ‘ä»¬å¯¹äºæ•°æ®åˆ’åˆ†è¯´æ˜ï¼š
```text
datasets/
â”œâ”€â”€ train/     # è®­ç»ƒé›† - ç”¨äºæ¨¡å‹è®­ç»ƒ
â”œâ”€â”€ val/       # éªŒè¯é›† - ç”¨äºè¶…å‚æ•°è°ƒä¼˜
â””â”€â”€ test/      # æµ‹è¯•é›† - ç”¨äºæœ€ç»ˆæ€§èƒ½è¯„ä¼°
```
åˆ’åˆ†æ¯”ä¾‹: è®­ç»ƒé›†80%ï¼ŒéªŒè¯é›†20%ï¼Œæµ‹è¯•é›†20%

âš™ï¸ ç¯å¢ƒé…ç½®
ç¡¬ä»¶è¦æ±‚
GPU: NVIDIA GeForce RTX 4090 (æˆ–åŒç­‰ç®—åŠ›æ˜¾å¡)

æ˜¾å­˜: â‰¥ 24GB

å†…å­˜: â‰¥ 32GB

è½¯ä»¶ç¯å¢ƒ
# åˆ›å»ºcondaç¯å¢ƒ
```text
conda create -n deepfake_detect python=3.8
conda activate deepfake_detect
```

# å®‰è£…PyTorch (CUDA 12.0)
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121

# å®‰è£…é¡¹ç›®ä¾èµ–
```text
absl-py==2.3.1
addict==2.4.0
basicsr==1.4.2
cachetools==5.5.2
certifi==2025.10.5
charset-normalizer==3.4.4
clip-anytorch==2.6.0
cmake==4.1.2
filelock==3.16.1
fsspec==2025.3.0
ftfy==6.2.3
future==1.0.0
google-auth==2.43.0
google-auth-oauthlib==1.0.0
grpcio==1.70.0
idna==3.11
imageio==2.35.1
importlib-metadata==8.5.0
jinja2==3.1.6
joblib==1.4.2
lazy-loader==0.4
lit==18.1.8
lmdb==1.7.5
markdown==3.7
markupsafe==2.1.5
mpmath==1.3.0
networkx==3.1
numpy==1.24.4
nvidia-cublas-cu12==12.1.3.1
nvidia-cuda-cupti-cu12==12.1.105
nvidia-cuda-nvrtc-cu12==12.1.105
nvidia-cuda-runtime-cu12==12.1.105
nvidia-cudnn-cu12==9.1.0.70
nvidia-cufft-cu12==11.0.2.54
nvidia-curand-cu12==10.3.2.106
nvidia-cusolver-cu12==11.4.5.107
nvidia-cusparse-cu12==12.1.0.106
nvidia-nccl-cu12==2.20.5
nvidia-nvjitlink-cu12==12.9.86
nvidia-nvtx-cu12==12.1.105
oauthlib==3.3.1
opencv-python==4.12.0.88
packaging==25.0
pillow==10.4.0
platformdirs==4.3.6
protobuf==5.29.5
pyasn1==0.6.1
pyasn1-modules==0.4.2
pywavelets==1.4.1
pyyaml==6.0.3
regex==2024.11.6
requests==2.32.4
requests-oauthlib==2.0.0
rsa==4.9.1
scikit-image==0.21.0
scikit-learn==1.3.2
scipy==1.10.1
sympy==1.13.3
tb-nightly==2.14.0a20230808
tensorboard-data-server==0.7.2
tensorboardx==2.6.2.2
threadpoolctl==3.5.0
tifffile==2023.7.10
tomli==2.3.0
torch==2.0.0+cu118
torchaudio==2.4.1+cu118
torchvision==0.15.1+cu118
tqdm==4.67.1
triton==2.0.0
typing-extensions==4.13.2
urllib3==2.2.3
wcwidth==0.2.14
werkzeug==3.0.6
yapf==0.43.0
zipp==3.20.2
```
ğŸš€ æ¨¡å‹è®­ç»ƒä¸æµ‹è¯•
```text
æ¨¡å‹è®­ç»ƒ
python train.py \
    --name=clip_vitl14 \
    --wang2020_data_path=datasets/ \
    --data_mode=wang2020 \
    --arch=CLIP:ViT-L/14 \
    --fix_backbone
```
å…³é”®å‚æ•°è¯´æ˜:
```text
--name: å®éªŒåç§°ï¼Œç”¨äºåˆ›å»ºä¿å­˜ç›®å½•

--wang2020_data_path: æ•°æ®é›†è·¯å¾„

--arch: æ¨¡å‹æ¶æ„ï¼Œä½¿ç”¨CLIP ViT-L/14

--fix_backbone: å†»ç»“ä¸»å¹²ç½‘ç»œå‚æ•°
```
æ¨¡å‹éªŒè¯
```text
python validate.py \
    --arch=CLIP:ViT-L/14 \
    --ckpt=checkpoints/clip_vitl14/model_epoch_best.pth \
    --result_folder=your_result_folder
```
å‚æ•°è¯´æ˜:

--ckpt: è®­ç»ƒå¥½çš„æ¨¡å‹æ£€æŸ¥ç‚¹è·¯å¾„

--result_folder: ç»“æœä¿å­˜ç›®å½•

æ€§èƒ½æŒ‡æ ‡
è®­ç»ƒæ—¶é•¿: ~48å°æ—¶ (RTX 4090)

æ¨ç†é€Ÿåº¦: ~15ms/å›¾åƒ

å³°å€¼æ˜¾å­˜: 18GB

ğŸ”„ å¤ç°æµç¨‹
å®Œæ•´å¤ç°æ­¥éª¤ï¼š
ç¯å¢ƒå‡†å¤‡
```text
conda create -n deepfake_detect python=3.8
conda activate deepfake_detect
pip install -r requirements.txt
```
æ•°æ®å‡†å¤‡ï¼š
ä¸‹è½½æ•°æ®é›†åˆ°datasetsç›®å½•
# ç¡®ä¿ç›®å½•ç»“æ„æ­£ç¡®
æ¨¡å‹è®­ç»ƒï¼š
python train.py --name=clip_vitl14 --wang2020_data_path=datasets/ --data_mode=wang2020 --arch=CLIP:ViT-L/14 --fix_backbone

æ¨¡å‹æµ‹è¯•ï¼š
python validate.py --arch=CLIP:ViT-L/14 --ckpt=checkpoints/clip_vitl14/model_epoch_best.pth --result_folder=your_result_folder

æˆ‘ä»¬è¿˜æä¾›å¿«é€ŸéªŒè¯çš„æ–¹æ³•ï¼š
# ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹å¿«é€Ÿæµ‹è¯•
python validate.py --ckpt=pretrained_models/best_model.pth --data_dir=datasets/test

âš™ï¸ ç¯å¢ƒé…ç½®
```text
å®éªŒè¦æ±‚ï¼š
GPUå‹å·	NVIDIA GeForce RTX 4090
æ˜¾å­˜	24 GB
CUDA Version	â‰¥ 12.0
GPUé©±åŠ¨ç‰ˆæœ¬	NVIDIA 575.57.08
```
ä¾èµ–å®‰è£…
# åˆ›å»ºcondaç¯å¢ƒ
```text
conda create -n deepfake_detect python=3.8
conda activate deepfake_detect
```
# å®‰è£…PyTorch (CUDA 12.0)
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121

# å®‰è£…é¡¹ç›®ä¾èµ–
```text
pip install -r requirements.txt
requirements.txt å…·ä½“å†…å®¹è§å‰é¢
```
ğŸš€ æ¨¡å‹è®­ç»ƒä¸æµ‹è¯•
æ€§èƒ½æŒ‡æ ‡
å®Œæ•´è®­ç»ƒæ—¶é•¿: çº¦48å°æ—¶ï¼ˆåœ¨RTX 4090ä¸Šï¼‰


